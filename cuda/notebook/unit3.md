---
title: CUDA执行模型
categories:
    - cuda
---
1. 概述
2. 线程束

<!-- more -->

# 概述

### 流式多处理器

1. 基本定义

* **SM** ：流式多处理器（Streaming Multiprocessor）是NVIDIA GPU的基本计算单元。每个SM可以并行执行多个线程。
* **SP** ：流处理器（Streaming Processor），也称为CUDA核心（CUDA core），是GPU最基本的处理单元。每个SP可以在一个时钟周期内执行一个线程。

2. 线程束（Warp）

* **Warp** ：一个线程束由32个线程组成，它们会被同时调度到一个SM上执行。这32个线程执行相同的指令但对不同的数据，即SIMD（单指令多数据）的并行执行模式。

3. 块与SM的关系

* **线程块** ：当我们在CUDA中启动一个内核，线程块会被分派到可用的SM上执行。一个SM可以同时执行多个线程块，但一个线程块在其生命周期中只会执行在一个SM上。
* **资源限制** ：一个SM上可以运行的线程数受到其寄存器和共享内存的限制。

4. 资源分配

* **寄存器和共享内存** ：每个SM都有一定数量的寄存器、共享内存、L1缓存和其他资源。线程块内的线程共享这些资源。寄存器和共享内存的使用量决定了一个SM上可以执行的最大线程和线程块数量。

5. 调度与执行

* **调度器** ：SM包含一个或多个调度器，它们会从多个线程束中选择线程束进行执行。当一个线程束在等待某事件（例如内存读取）时，调度器可以快速切换到另一个线程束，以保持ALUs的忙碌并隐藏延迟。

### SM和SP的关系

1. **SP（Streaming Processor）** ：

* **定义** ：SP 是 GPU 最基本的处理单元，也称为 CUDA core。它是执行具体计算任务的单元，类似于 CPU 中的 ALU（算术逻辑单元）。
* **功能** ：SP 负责执行浮点和整数运算。在某些架构中，SP 也支持特殊函数单元（SFU）的计算，如三角函数、指数函数等。

1. **SM（Streaming Multiprocessor）** ：

* **定义** ：SM 是由多个 SP 组成的更大的处理单元。它不仅包含多个 SP，还包含其他资源，如寄存器文件、共享内存、L1 缓存、Warp 调度器等。
* **功能** ：SM 负责调度和管理线程块（block）中的线程（thread）。它将线程组织成线程束（Warp），每个 Warp 包含 32 个线程。SM 的 Warp 调度器负责将这些 Warp 分配到 SP 上执行。

#### 关系总结

* **多个 SP 组成一个 SM** ：一个 SM 由多个 SP 组成，具体数量取决于 GPU 的架构。例如，Fermi 架构的 SM 包含 32 个 SP，Kepler 架构的 SM 包含 192 个 SP，Maxwell 架构的 SM 包含 128 个 SP。
* **SM 调度线程** ：SM 负责调度和管理线程块中的线程。它将线程组织成 Warp，每个 Warp 包含 32 个线程。这些 Warp 被分配到 SM 中的 SP 上执行。
* **资源分配** ：SM 包含寄存器文件、共享内存、L1 缓存等资源，这些资源被分配给驻留在 SM 中的线程。

#### 示例

假设我们有一个 Fermi 架构的 GPU，其 SM 配置如下：

* 每个 SM 包含 32 个 SP。
* 每个 SM 包含 64 KB 的寄存器文件和 16 KB 的共享内存。
* 每个 SM 可以同时执行多个线程块，但每个线程块必须完全驻留在一个 SM 中。

当一个 CUDA 核函数启动时，线程块会被分配到不同的 SM 上执行。每个线程块中的线程会被组织成多个 Warp，每个 Warp 包含 32 个线程。这些 Warp 会被 SM 的 Warp 调度器分配到 SP 上执行。

### Wrap和SP关系

* **Warp执行** ：一个Warp中的32个线程会被分配到一个SM中的多个SP上执行。例如，如果一个SM有32个SP，那么一个Warp中的32个线程可以同时在一个时钟周期内被处理，每个SP处理一个线程。
* **多Warp调度** ：SM的Warp调度器会从多个Warp中选择一个Warp来执行。当一个Warp中的线程在等待内存操作或其他延迟操作时，调度器可以切换到另一个Warp，以保持SP的忙碌并隐藏延迟。

### SM的调度和执行机制

> 两个线程束调度器选择两个线程束，再把一个指令从线程束中发送到一个组上，组里有16个CUDA核心，16个加载/存储单元或四个特殊指令单元。

1. 两个线程束调度器选择两个线程束

   * 线程束调度器：每个SM包含一个或多个线程束调度器，负责从就绪队列中选择线程束（Warp）进行执行。就绪队列中包含所有已经准备好执行的线程束。
   * 选择两个线程束 ：如果有两个线程束调度器，它们可以同时选择两个线程束。这意味着在每个时钟周期内，两个线程束调度器可以分别选择一个线程束进行执行。
2. 再把一个指令从线程束中发送到一个组上

   - 指令分发：线程束调度器选择一个线程束后，会从该线程束中取出一个指令，并将这个指令发送到一个执行组上；
   - 执行组：执行组是SM中的一个逻辑单元，负责执行线程束中的指令；
3. 组里有16个CUDA核心，16个加载/存储单元或四个特殊指令单元

   - 16个CUDA核心：执行组包含16个CUDA核心，这些核心负责执行计算密集型操作，如浮点和整型运算；
   - 16个加载/存储单元：这些单元负责执行内存访问操作，如加载和存储数据；
   - 4个特殊指令单元：这些单元负责执行特殊函数，如三角函数，指数函数等；

第一个疑问点：执行组1包含16个CUDA核心，线程束调度器1选择线程束1，16个核心可以处理一个线程束吗？

1. 执行组的并行处理
   * 执行组：执行组包含16个CUDA核心，这些核心可以同时处理一个Wrap中的16个线程；
   * 分批处理：一个Wrap中的32个线程可以被分成两批，没批16个线程，在每个时钟周期内，16个CUDA核心处理第一批16个线程，然后在下一个始终周期内处理第二批16个线程；
2. 具体执行过程
   * 第一个时钟周期：
     * 16个CUDA核心同时处理Warp中的前16个线程；
     * 这16个线程执行相同的指令，但对不同的数据；
   * 第二个时钟周期：
     * 16个CUDA核心同时处理Warp中的后16个线程；
     * 这16个线程执行相同的指令，但对不同的数据；
