---
title: CUDA执行模型
categories:
    - cuda
---
1. 概述
2. 线程束

<!-- more -->

# 概述

### 1. 流式多处理器

1. 基本定义

* SM ：流式多处理器（Streaming Multiprocessor）是NVIDIA GPU的基本计算单元。每个SM可以并行执行多个线程。
* SP ：流处理器（Streaming Processor），也称为CUDA核心（CUDA core），是GPU最基本的处理单元。每个SP可以在一个时钟周期内执行一个线程。

2. 线程束（Warp）

* Warp ：一个线程束由32个线程组成，它们会被同时调度到一个SM上执行。这32个线程执行相同的指令但对不同的数据，即SIMD（单指令多数据）的并行执行模式。

3. 块与SM的关系

* 线程块 ：当我们在CUDA中启动一个内核，线程块会被分派到可用的SM上执行。一个SM可以同时执行多个线程块，但一个线程块在其生命周期中只会执行在一个SM上。
* 资源限制 ：一个SM上可以运行的线程数受到其寄存器和共享内存的限制。

4. 资源分配

* 寄存器和共享内存 ：每个SM都有一定数量的寄存器、共享内存、L1缓存和其他资源。线程块内的线程共享这些资源。寄存器和共享内存的使用量决定了一个SM上可以执行的最大线程和线程块数量。

5. 调度与执行

* 调度器 ：SM包含一个或多个调度器，它们会从多个线程束中选择线程束进行执行。当一个线程束在等待某事件（例如内存读取）时，调度器可以快速切换到另一个线程束，以保持ALUs的忙碌并隐藏延迟。

### 2. SM和SP的关系

1. **SP（Streaming Processor）** ：

* **定义** ：SP 是 GPU 最基本的处理单元，也称为 CUDA core。它是执行具体计算任务的单元，类似于 CPU 中的 ALU（算术逻辑单元）。
* **功能** ：SP 负责执行浮点和整数运算。在某些架构中，SP 也支持特殊函数单元（SFU）的计算，如三角函数、指数函数等。

1. **SM（Streaming Multiprocessor）** ：

* **定义** ：SM 是由多个 SP 组成的更大的处理单元。它不仅包含多个 SP，还包含其他资源，如寄存器文件、共享内存、L1 缓存、Warp 调度器等。
* **功能** ：SM 负责调度和管理线程块（block）中的线程（thread）。它将线程组织成线程束（Warp），每个 Warp 包含 32 个线程。SM 的 Warp 调度器负责将这些 Warp 分配到 SP 上执行。

#### 2.1 关系总结

* **多个 SP 组成一个 SM** ：一个 SM 由多个 SP 组成，具体数量取决于 GPU 的架构。例如，Fermi 架构的 SM 包含 32 个 SP，Kepler 架构的 SM 包含 192 个 SP，Maxwell 架构的 SM 包含 128 个 SP。
* **SM 调度线程** ：SM 负责调度和管理线程块中的线程。它将线程组织成 Warp，每个 Warp 包含 32 个线程。这些 Warp 被分配到 SM 中的 SP 上执行。
* **资源分配** ：SM 包含寄存器文件、共享内存、L1 缓存等资源，这些资源被分配给驻留在 SM 中的线程。

#### 2.1 示例

假设我们有一个 Fermi 架构的 GPU，其 SM 配置如下：

* 每个 SM 包含 32 个 SP。
* 每个 SM 包含 64 KB 的寄存器文件和 16 KB 的共享内存。
* 每个 SM 可以同时执行多个线程块，但每个线程块必须完全驻留在一个 SM 中。

当一个 CUDA 核函数启动时，线程块会被分配到不同的 SM 上执行。每个线程块中的线程会被组织成多个 Warp，每个 Warp 包含 32 个线程。这些 Warp 会被 SM 的 Warp 调度器分配到 SP 上执行。

### 3. Wrap和SP关系

* **Warp执行** ：一个Warp中的32个线程会被分配到一个SM中的多个SP上执行。例如，如果一个SM有32个SP，那么一个Warp中的32个线程可以同时在一个时钟周期内被处理，每个SP处理一个线程。
* **多Warp调度** ：SM的Warp调度器会从多个Warp中选择一个Warp来执行。当一个Warp中的线程在等待内存操作或其他延迟操作时，调度器可以切换到另一个Warp，以保持SP的忙碌并隐藏延迟。

### 4. SM的调度和执行机制

> 两个线程束调度器选择两个线程束，再把一个指令从线程束中发送到一个组上，组里有16个CUDA核心，16个加载/存储单元或四个特殊指令单元。

1. 两个线程束调度器选择两个线程束

   * 线程束调度器：每个SM包含一个或多个线程束调度器，负责从就绪队列中选择线程束（Warp）进行执行。就绪队列中包含所有已经准备好执行的线程束。
   * 选择两个线程束 ：如果有两个线程束调度器，它们可以同时选择两个线程束。这意味着在每个时钟周期内，两个线程束调度器可以分别选择一个线程束进行执行。
2. 再把一个指令从线程束中发送到一个组上

   - 指令分发：线程束调度器选择一个线程束后，会从该线程束中取出一个指令，并将这个指令发送到一个执行组上；
   - 执行组：执行组是SM中的一个逻辑单元，负责执行线程束中的指令；
3. 组里有16个CUDA核心，16个加载/存储单元或四个特殊指令单元

   - 16个CUDA核心：执行组包含16个CUDA核心，这些核心负责执行计算密集型操作，如浮点和整型运算；
   - 16个加载/存储单元：这些单元负责执行内存访问操作，如加载和存储数据；
   - 4个特殊指令单元：这些单元负责执行特殊函数，如三角函数，指数函数等；

第一个疑问点：执行组1包含16个CUDA核心，线程束调度器1选择线程束1，16个核心可以处理一个线程束吗？

1. 执行组的并行处理
   * 执行组：执行组包含16个CUDA核心，这些核心可以同时处理一个Wrap中的16个线程；
   * 分批处理：一个Wrap中的32个线程可以被分成两批，没批16个线程，在每个时钟周期内，16个CUDA核心处理第一批16个线程，然后在下一个始终周期内处理第二批16个线程；
2. 具体执行过程
   * 第一个时钟周期：
     * 16个CUDA核心同时处理Warp中的前16个线程；
     * 这16个线程执行相同的指令，但对不同的数据；
   * 第二个时钟周期：
     * 16个CUDA核心同时处理Warp中的后16个线程；
     * 这16个线程执行相同的指令，但对不同的数据；

# 配置文件驱动优化

1. 配置文件驱动优化是什么？
2. 三种常见的限制内核性能的因素：
   1. 存储带宽
   2. 计算资源
   3. 指令和内存延迟
3. 怎么通过性能指标来优化？

# 线程束

1. 什么是线程束？
   线程束是SM中最基本的执行单元
2. 如果线程块的大小不是线程束的整数倍，怎么分配？

# SM的关键组件

- CUDA核心
- 寄存器文件
- 共享内存/一级缓存

### 1. CUDA核心

执行指令的基本单元，相当于CPU中的ALU（算术逻辑单元），每个CUDA核心负责一个线程的指令执行；

### 2. 寄存器

寄存器是SM中速度最快，容量最小的内存空间。每个线程拥有自己的寄存器文件，用于存储线程中的局部变量，中间计算结果以及函数参数。寄存器大小通常是32KB，64KB；

### 3. 共享内存

共享内存是SM内多个线程可以共享访问的一块内存，用于存储线程块中所有线程的共享数据，共享内存的访问速度比全局内存块，比寄存器慢，共享内存的大小通常为16KB，32KB或64KB；线程块内的线程可以通过共享内存快速交换数据，减少对全局内存的访问次数。

- 线程间通信：线程可以通过共享内存高效地交换数据；
- 数据缓存：将频繁访问的全局内存数据复制到共享内存中，可以减少对全局内存的访问次数，提高性能；
- 协同计算：线程可以协同使用共享内存来完成某些计算任务；

### 4. SM架构流程

1. 线程块调度：CUDA运行时系统将线程块分配给可用的SM；
2. 寄存器分配：线程调度器分配寄存器给每个线程，用于存储局部变量，函数参数和返回值；
3. 共享内存分配：线程调度分配共享内存给线程块中的所有线程共享的数据；
4. 线程束执行：SM将线程块中的线程组织成线程束，每个线程束由32个连续线程组成，线程束是SM中并行执行的基本单位。（在一个线程束中，所有线程按照单指令多线程的方式执行，即32个线程都执行相同的指令，每个线程在私有数据上进行操作。）
5. 指令发射：SM并行的向线程束中的所有线程发射相同的指令，如果线程束中的线程执行不同的代码路径（一段代码在运行时可能经过的逻辑顺序或流程）（线程分化），则会降低效率；
6. 结果存储：线程将计算结果存储到全局内存或寄存器中；
7. 线程块完成：当线程块中的所有线程完成执行后，SM回调度下一个线程块；

# GPU内存层次结构

- 寄存器
- 共享内存
- 全局内存
- 常量内存
- 纹理内存
- 本地内存

### 1. 全局内存

- 位于GPU的芯片外部，所有线程都可以访问；
- 相对较大，但是访问速度较慢，具有较高的访问延迟；
- 访问模式应尽量连续和对其，以充分利用内存带宽；
- 用于存储需要在多个线程块之间共享的数据，访问速度较慢，但容量大

### 2. 常量内存

- 只读内存，适用于存储不变的数据；
- 常量内存在硬件上有一个单独的缓存，访问速度块；

### 3. 纹理内存

- 类似于制度缓存，适用于特殊的纹理操作；
- 常用于图像处理，因为其缓存优化了二位空间访问；

# GPU与CPU的协作

1. 异步操作：GPU和CPU同时执行不同的任务，通过CUDA流实现异步数据传输和内核执行；
2. 数据传输：GPU和CPU之间的数据是通过PCIe总线进行的，速度相对较慢，应尽量减少数据传输，或者使用异步数据传输来隐藏传输延迟；
3. 任务划分：将计算密集型任务交给GPU处理，而将控制逻辑和轻量级任务交给CPU；

# 再谈SM

### 1. CUDA核心（SP）

- 整数运算单元
- 浮点数运算单元
- 双精度运算单元
- 特殊函数单元

### 2. 调度器和派发单元

- Wrap调度器
  - 负责选择就绪的Wrap进行执行；
  - 负责实现零开销的上下文切换；
  - 维护Wrap的执行状态和程序计数器；
- 指令缓存
  - 存储即将执行的指令；
  - 减少指令获取延迟；
- 指令派发单元
  - 将指令分给相应的执行单元；

### 3. 内存子系统

- L1缓存
  - 可配置大小，通常16KB-48KB
  - 与共享内存共享物理空间；
  - 用于缓存全局内存访问；
- 共享内存控制器
  - 管理共享内存的访问；
  - 处理bank冲突；
  - 实现内存对齐；
