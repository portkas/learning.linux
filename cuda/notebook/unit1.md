---
title: 基于cuda的异构并行计算
categories:
    - cuda
---
1. 并行计算
2. 异构计算
3. 简单示例

<!-- more -->

# 并行计算

相关概念：

* 数据相关性：一个指令处理前一个指令产生的数据。
* 并行性：任务并行，数据并行
* 带宽：单位时间内，可以处理的数据量（MB/s，GB/s）
* 吞吐量：单位时间内成功处理的运算数量（gflops）
* 计算机架构：单指令单数据(SISD)，单指令多数据（SIMD），多指令单数据（MISD），多指令多数据（MIMD）

数据并行程序设计：

* 第一步：把数据依据线程进行划分，使每个线程处理一部分数据。
  * 块划分：一组连续的数据被分到一个块内，每个数据块以任意次序被安排给一个线程，线程通常在同一时间只处理一个数据块。
  * 周期划分：更少的数据被分到一个块内，相邻的线程处理相邻的数据块，每个线程可以处理多个数据块。

计算机架构：

- 根据指令和数据划分：
  - 单指令单数据(SISD)：串行架构，只有一个核心，任何时间点上都只有一个指令流在处理一个数据流；
  - 单指令多数据(SIMD)：并行架构，有多个核心，在任何时间点上所有核心只有一个指令流处理不同的数据流；
  - 多指令单数据(MISD)：每个核心通过使用多个指令流处理同一个数据流；
  - 多指令多数据(MIMD)：并行架构，多个核心使用多个指令流来异步处理多个数据流；
- 根据内存组织方式划分：
  - 分布式内存的多节点系统：每个处理器有自己的本地内存，并且处理器之间可以通过网络通信；
  - 共享内存的多处理器系统：多个处理器之间与同一个物理内存相关联或公用一个低延迟的链路；

# 异构计算

- 同构计算：使用同一架构下的一个或多个处理器来执行一个应用；
- 异构计算：使用一个处理器架构来执行一个应用，为任务选择适合它的架构；

描述GPU容量的两个重要特征：

- CUDA核心数量
- 内存大小

评估GPU的性能指标：

- 峰值计算性能：每秒能处理的单精度或双精度浮点运算的数量；
- 内存带宽：从内存中读取或写入数据的比率；

CPU线程与GPU线程：

- CPU线程：重量级实体，上下文切换缓慢且开销大；
- GPU线程：高度轻量级，有成千上万的线程排队等待工作，一个线程结束，只要调用另一组线程执行其他程序即可；

CUDA：

- 一种通用的并行计算平台和编译模型；
- CUDA提供了两层API来管理设备和组织线程：
  - CUDA驱动API：低级API，较难编程，但是提供了更多的控制；
  - CUDA运行时API：高级API，在驱动API上层实现，每个运行时API函数被分解为更多传给驱动API；
- 两种API是互相排斥的，不能混和调用；
- NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来；


# 简单示例

```cpp
#include <stdio.h>

// __global__修饰符告诉编译器这个函数将会从GPU中调用，在GPU上执行
__global__ void helloFromGPU(){
    printf("Hello World from GPU!\n");
}

int main(){
    printf("Hello World from CPU!\n");
    // 启动内核函数；
    // 三重尖括号意味着从主线程到设备端代码的调用；
    // 一个内核函数通过一组线程来执行，所有线程执行相同的代码；
    // 有十个线程被调用；
    helloFromGPU <<<1, 10>>>();
    // 显式地释放和清空当前进程中与当前设备有关的所有资源；
    cudaDeviceReset();
    return 0;
}

// $ nvcc -arch sm_80 helloFromGPU.cu -o hello
// GeForce RTX 4070 是基于 NVIDIA 的 Ada Lovelace 架构
// -arch sm_80使编译器为Ada lovelace架构生成设备代码；
```

CUDA编程结构：

1. 分配GPU内存；
2. 从CPU内存中拷贝数据到GPU内存；
3. 调用CUDA内核函数来完成指定的运算；
4. 将数据从GPU拷贝回CPU内存；
5. 释放GPU内存空间；
